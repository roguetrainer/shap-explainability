{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finance Use Case: Loan Approval Explanation\n",
    "\n",
    "**Goal:** Explain why a specific loan applicant was rejected (or predicted to default) using SHAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize JS\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Synthetic Data\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"Income_Annual\": np.random.normal(50000, 15000, n_samples).astype(int),\n",
    "    \"Credit_Score\": np.random.normal(650, 100, n_samples).astype(int),\n",
    "    \"Debt_to_Income\": np.random.uniform(0.1, 0.6, n_samples),\n",
    "    \"Loan_Amount\": np.random.normal(15000, 5000, n_samples).astype(int),\n",
    "    \"Years_Employed\": np.random.randint(0, 20, n_samples),\n",
    "    \"Has_Prior_Default\": np.random.choice([0, 1], n_samples, p=[0.9, 0.1])\n",
    "})\n",
    "\n",
    "risk_score = (\n",
    "    (data[\"Debt_to_Income\"] * 100) - \n",
    "    (data[\"Credit_Score\"] / 10) - \n",
    "    (data[\"Income_Annual\"] / 2000) + \n",
    "    (data[\"Has_Prior_Default\"] * 50)\n",
    ")\n",
    "risk_score += np.random.normal(0, 10, n_samples)\n",
    "data[\"Defaulted\"] = (risk_score > -20).astype(int)\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "model.fit(data.drop(\"Defaulted\", axis=1), data[\"Defaulted\"])\n",
    "print(\"Model Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute Shapley Values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(data.drop(\"Defaulted\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Global Interpretability\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.plots.beeswarm(shap_values, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Local Interpretability (Waterfall)\n",
    "high_risk_idx = np.where(data[\"Defaulted\"] == 1)[0][0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.plots.waterfall(shap_values[high_risk_idx], show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
